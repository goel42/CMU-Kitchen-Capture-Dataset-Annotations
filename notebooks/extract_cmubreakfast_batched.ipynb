{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from datetime import datetime\n",
    "\n",
    "from pretrainedmodels import bninception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader(Dataset):\n",
    "    def __init__(self, frames_dir):\n",
    "        self.frames_dir = frames_dir\n",
    "        self.frames = glob(os.path.join(self.frames_dir, \"*.jpg\"))\n",
    "        self.frames_count = len(self.frames)\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize([256, 454]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x[[2,1,0],...]*255), #to BGR\n",
    "            transforms.Normalize(mean=[104, 117, 128],std=[1, 1, 1]),\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        file_name = str(idx)+\".jpg\"\n",
    "        file_path = os.path.join(self.frames_dir, file_name)\n",
    "        \n",
    "        frame = cv2.imread(file_path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        frame = Image.fromarray(frame)\n",
    "        frame = self.transform(frame) #to device cuda?#DOUBT?\n",
    "        \n",
    "        return frame, idx\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.frames_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = bninception(pretrained=None)\n",
    "state_dict = torch.load('rulstm/FEATEXT/models/TSN-rgb.pth.tar', map_location='cpu')['state_dict']\n",
    "state_dict = {k.replace('module.base_model.','') : v for k,v in state_dict.items()}\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "model.last_linear = nn.Identity()\n",
    "model.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s = 32\n",
    "activity = \"Brownie\"\n",
    "src_vids_path = os.path.join(\"/home/anujraj/cmu-kitchen-capture/raw/\", activity)\n",
    "dest_feats_path = os.path.join(\"/home/anujraj/cmu-kitchen-capture/features2/\", activity)\n",
    "if not os.path.exists(dest_feats_path):\n",
    "    os.makedirs(dest_feats_path)\n",
    "\n",
    "subjects = os.listdir(src_vids_path)\n",
    "subjects = [subject for subject in subjects if \"Video\" in subject]\n",
    "subjects = sorted(subjects)\n",
    "\n",
    "\n",
    "for subject in subjects:\n",
    "        spath = os.path.join(src_vids_path, subject)\n",
    "        \n",
    "        viewpoints = os.listdir(spath)\n",
    "        viewpoints = [viewpoint for viewpoint in viewpoints if \".avi\" in viewpoint]\n",
    "        for viewpoint in viewpoints:\n",
    "            feat_filename = viewpoint.split(\"-\")[0]\n",
    "            print(\"Started extracting feats for: \", feat_filename)\n",
    "            feat_dim = 1024\n",
    "            \n",
    "            dataset = ImageLoader(os.path.join(src_vids_path, subject, viewpoint.split(\".\")[0]))\n",
    "            total_frames = len(dataset)\n",
    "            \n",
    "            feats = np.zeros((total_frames, 1024))\n",
    "            trainloader = DataLoader(dataset, batch_size=batch_s, shuffle=False, num_workers=16, drop_last=False)\n",
    "            \n",
    "            for i, data in enumerate(trainloader):\n",
    "                frames, frames_indices = data\n",
    "                frames = frames.to(device)\n",
    "                \n",
    "                curr_feats = model(frames)\n",
    "                \n",
    "                for j in range(frames.shape[0]):\n",
    "                    feats[frames_indices[j]] = curr_feats[j].cpu().detach().numpy()\n",
    "            \n",
    "            np.save(os.path.join(dest_feats_path, feat_filename+\".npy\"), feats)\n",
    "            print(\"Completed: \", feat_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
